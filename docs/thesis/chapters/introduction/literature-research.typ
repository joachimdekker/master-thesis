#import "../../utils/cite-tools.typ": citeauthor

= Related Work
As far as we know, this is the first work that compiles Excel to another source language. In this section, we present related work that could help this thesis. We first discuss function extraction, which extract the computational model from Excel to another representation. Then, we discuss ways to validate Excel. We cover different techniques of source-to-source compilation, and finally discuss what it means to have 'idiomatic' code.

== Function Extraction
#citeauthor(<lano_agile_2017>) describe a way to convert an excel application to code by extracting a UML diagram out of a spreadsheet and converting it to code, but the whole process is manual.

Object oriented models are often used to validate spreadsheets to reduce errors @engels_classsheets_2005, @cunha_spreadsheet_2015. The automated extraction of such a model is also proposed by #citeauthor(<cunha_automatically_2010>), where functional dependencies are used to detect dependencies between columns like in database normalisation, and construct a model of this. They augment this with OCL to also describe the models constraints @cunha_relational_2012. In relation to this research, these works see spreadsheets as databases with relational mappings, while our research only considers the semantic computational model of Excel.

#citeauthor(<sestoft_spreadsheet_2006>) describes a full alternative implementation of spreadsheets, with subsequent master theses expanding upon the work @iversen_runtime_2006 @poulsen_optimized_2007 describe how to efficiently calculate the values in a spreadsheet using the support graph: a more organised version of the functional dependencies used in @cunha_automatically_2010. In comparison with #citeauthor(<cunha_automatically_2010>), these works also consider transitive dependencies in their model. Furthermore, they only represent the calculations, but do not generate code except for @iversen_runtime_2006. #citeauthor(<iversen_runtime_2006>) expands upon the work of #citeauthor(<sestoft_spreadsheet_2006>) by introducing runtime code generation for speeding up parts of the calculations.

Outside the literature, few packages exist that support calling excel calculations. EPPlus @epplus_software_epplus_nodate, Espose Cells @aspose_espose_nodate, Apache POI @apache_software_apache_nodate, and SyncFusion @syncfusion_syncfusion_nodate all use their own calculation engine based on the dependencies, but do not use a support graph like in @sestoft_spreadsheet_2006. These tools use the same interpreting technique as Excel, and do not utilise source code generation like this thesis.

== Validation
To verify the semantics of the program, the semantics of Excel should be defined so they can be compared with the semantics of the higher level language.

#citeauthor(<bock_semantics_2020>) defines the operational semantics for a self-made spreadsheet framework @sestoft_sheet-defined_2013 which closely reflects and closely resembles the Excel semantics. The semantics could serve as a starting point for verifying the compiler steps from Excel formulas to generated code, but need alteration because it is not clear if they fully model the excel semantics.

#citeauthor(<steinhofel_modular_2018>) describes validation of source-to-source compilation using symbolic execution, where the program is 'executed' using inference rules to create a symbolic execution tree that can be used to compare the two sources. If their symbolic execution tree is equivalent, the programs are considered equivalent @steinhofel_modular_2018. While the formal verification of the compiler is a good idea, we acknowledge that this is too big for the scope of this master project.

A more manageable verification is empirical verification. #citeauthor(<rothermel_methodology_2001>) and #citeauthor(<fisher_automated_2002>) introduce the _What You See Is What You Test_ (WYSIWYT) framework for spreadsheet testing which sets it apart as emperical verification for spreadsheets. It utilises definition-use (du) associations to link formulas to their computational or predicate uses. A spreadsheet is considered 'validated' when all du-associations are exercised by at least one test. While users can manually validate du-associations @rothermel_methodology_2001, the framework also supports generating automated test cases using random or goal-oriented approaches to satisfy all du-associations @fisher_automated_2002. This idea can be applied to our research. For a good compilation, the generated code should pass all of these automated tests to be sufficiently verified.

// Translation Validation

== Source-to-source compilation
Source to source compilation, also called transpilation, transcompilation @roziere_unsupervised_2020, or program extraction, involves the translation of one higher-level source language to a target higher-level language. The compilation should, like a normal compiler, preserve the semantics. Several techniques have been implemented.

#citeauthor(<waters_program_1988>) and #citeauthor(<ordonez_camacho_automated_2010>) both describe _transliteration and refinement_, as well as _abstraction and reimplementation_ @waters_program_1988. Transliteration involves the translation of code line-by-line to a intermediate translated representation in the target language @waters_program_1988. The intermediate representation can then be refined to better source code @waters_program_1988. @ordonez_camacho_automated_2010 translate grammars through transliteration, converting one language to the other using simple rules. They allow the user to define exceptions, which serve the same role, albeit a bit more expressive than refinement. #citeauthor(<cockx_reasonable_2022>) use simple rules to translate Agda programs into Haskell programs, essentially only doing the transliteration step. Transliteration can be applied in our research, but it mostly works with source code that is alike in grammar and semantics @waters_program_1988.

_Abstraction and reimplementation_ is a more used method @waters_program_1988 @ordonez_camacho_automated_2010 @lopes_chomsky_2005. From the source language, an intermediary representation is extracted, such as ILR @ordonez_camacho_automated_2010 or UML+OCL @lano_using_2024. The intermediary representation is then converted to the target language @waters_program_1988. This method only needs $2n$ instead of $n(n-1)$ translators @ordonez_camacho_automated_2010 @lopes_chomsky_2005. This closely relates to our research, since we will be implementing a custom domain model that models the excel 

More recently, models trained on large corpora have become a dominant approach for source-to-source compilation @yang_exploring_2024 @roziere_unsupervised_2020 @chen_tree--tree_2018. These methods leverage the ability of LLMs to generalize across tasks without specific re-training and provide guidance in their shortcomings @yang_exploring_2024. #citeauthor(<yang_exploring_2024>) propose using test case generation to provide hints to repair incorrect translations. 
However, these models require lots of annotated data @roziere_unsupervised_2020. Hence, #citeauthor(<roziere_unsupervised_2020>) proposes a way to train a model with unsupervised data, by using large corpora of open source code and applying transformations on them. #citeauthor(<guo_graphcodebert_2020>) and #citeauthor(<chen_tree--tree_2018>) propose using the AST of the source code as an additional heuristic in transforming programs to reduce errors and improve translation. Since this novel approach increases readability, it does relate to our research. However, given the lack of relevant data, we think the method will be insufficient.

// == Mutual Recursion
// Since the research has a focus on calculating the fixpoint of mutual recursive formulas---formulas with a circular dependency---we look at the related work in this area.

// #citeauthor(<ushakova_verification_2018>) proposes a verification framework that merges multiple recursive entities into a unified recursive function. While this helps formal verification @ushakova_verification_2018, it also simplifies the generation of code, since there are fewer functions to be generated. #citeauthor(<yallop_generating_2019>) proposes a set of code generation techniques that leverage let-insertion to write mutually recursive code without scope extrusion. These techniques can be used when generating the code, but need modification since these works assume that we don't need the outcome of the individual mutual recursive formulas.

// In order to calculate the results of a mutual recursion, iterative algorithms can be used. We consider a function $F: RR^N -> RR^N$ for which we need to calculate $F(arrow(x)) = arrow(x)$, where $arrow(x)$ represents the $N$ intermediate values of every cell in the mutual recursion. Calculating the fixed point can be done linearly or non-linearly @kelley_iterative_1995. The simplest approach is Picard iteration, where we simply compute the next step in the sequence $arrow(x)_(t+1) = F(arrow(x)_t)$ @kelley_iterative_1995. Several variations of this method have been developed by different researchers to reduce the number of iterations. #citeauthor(<mann_mean_1953>), #citeauthor(<ishikawa_fixed_1974>), #citeauthor(<noor_new_2000>), #citeauthor(<phuengrattana_rate_2011>), #citeauthor(<khan_picard-mann_2013>), and #citeauthor(<thakur_new_2014>) use additional functions and blending techniques to improve convergence---all demonstrated to be faster than previous methods.

// The issue with most of the iterative methods described in this section is that they rely on multiple assumptions---the most significant being that they converge and are continuous. The Excel compilation must be capable of handling all inputs, including circular dependencies that do not converge or that involve conditional logic. Therefore, many of these optimizations are not applicable to our work.

== Idiomatic Code<sec:intro:idiomatic-code>
_Idiomatic_ means "containing expressions that are natural to a native speaker of a language" @lea_idiomatic_2025. While this definition is meant for natural languages, we can also extend it to programming languages: "containing expressions that are natural to a senior programmer writing the language".
While software engineers consider creating code as a big part of their job @jetbrains_software_2024, one universal definition of what is considered 'good' code is hard to determine. This was made clear by #citeauthor(<borstler_i_2018>) in their paper---aptly titled "I know it when I see it"---indicating that factors of code quality are diverse across demographics @borstler_i_2018. 

Yet, a plethora of books and papers have been written on what is considered good or idiomatic code @mcconnell_code_2004 @hunter-zinck_ten_2021 @fowler_refactoring_2019 @winter_agile_2014 @hunt_pragmatic_2011. #citeauthor(<borstler_developers_2023>) interviewed developers, students and educators on the factors of code quality. Comprehensibility and Structure were the most commonly named factors @borstler_developers_2023 @borstler_i_2018, which is confirmed in several other sources @mcconnell_code_2004 @hunter-zinck_ten_2021 @hunt_pragmatic_2011 @fowler_refactoring_2019 @winter_agile_2014. According to #citeauthor(<fowler_refactoring_2019>), structure directly relates to comprehensibility and readability since humans read code: if the code does not have structure, it will be harder to read and understand. They give an example where an extremely long function is harder to read than multiple shorter functions with one orchestrating function.

An important factor of structure is no duplication---commonly stated as DRY or 'Don't Repeat Yourself' @fowler_refactoring_2019 @hunt_pragmatic_2011 @borstler_developers_2023. Duplication can increase risks when a part of the duplicated code requires rework: often the duplicated part is forgotten and does not get updated @fowler_refactoring_2019 @hunt_pragmatic_2011. For example, when applying an operation on a list, it is very uncommon (and a bad code practice) to verbosely apply the operation to every array element. Instead, we use a for loop or map that loops over the list and applies the operation. 

All of these factors contribute to one larger code quality: readability @borstler_developers_2023 @borstler_i_2018 @hunter-zinck_ten_2021. According to #citeauthor(<fakhoury_measuring_2020>), readability influences cognitive load and performance of developers. Comprehensibility and structure are very important @borstler_developers_2023 @borstler_i_2018. Combined with reduced duplication it leads to better readability, which is something we want to achieve. 

More concretely: in this thesis, we consider 'good' code as code a senior developer would have written in their best language. Furthermore, we follow the style guide of the language, written by Microsoft @microsoft_net_2025. This style guide establishes that we need to use the newest language features, write clear, concise code, and adhere to the naming conventions. We acknowledge this is still vague and that idiomatic code is pretty subjective. We will give more examples of what we consider good C\# code in @sec:eval:readability.